{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Monitoring de Production et Detection de Data Drift\n",
    "\n",
    "## Contexte et demarche\n",
    "\n",
    "Dans le notebook precedent (`04_data_drift_analysis.ipynb`), nous avons etudie le concept de data drift en comparant nos donnees de train et de test. Cette analyse avait une limite importante : **les deux jeux de donnees proviennent du meme dataset Kaggle**, donc toute \"derive\" detectee est un artefact statistique, pas du vrai drift.\n",
    "\n",
    "En production reelle, le data drift est un phenomene **temporel** : la distribution des donnees recues par l'API change au fil du temps (evolution economique, nouveau segment de clientele, changement de fournisseur de donnees, etc.).\n",
    "\n",
    "### Ce que fait ce notebook\n",
    "\n",
    "Nous avons mis en place une **architecture complete de monitoring** :\n",
    "\n",
    "1. **Stockage en production** : chaque prediction de l'API est stockee dans **Neon Postgres** avec :\n",
    "   - Les **inputs** (419 features en JSONB)\n",
    "   - Les **outputs** (probabilite, decision)\n",
    "   - Le **temps d'execution** (inference_time_ms)\n",
    "   - Un **timestamp** (dimension temporelle)\n",
    "\n",
    "2. **Simulation de trafic** : le script `simulate_production_traffic.py` envoie des predictions par batches avec du drift progressif, reproduisant ce qui se passerait en production si la population de clients changeait.\n",
    "\n",
    "3. **Detection de drift** : le script `run_drift_detection.py` compare les features des predictions recentes (depuis Postgres) contre la distribution de reference (training data) via le test de Kolmogorov-Smirnov.\n",
    "\n",
    "4. **Collecte de logs** : Fluentd collecte les logs structures de l'API et les stocke dans Postgres.\n",
    "\n",
    "5. **Visualisation** : Grafana et Streamlit permettent de suivre le drift et les metriques operationnelles en temps reel.\n",
    "\n",
    "Ce notebook connecte directement a la base de production pour analyser les resultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Architecture de monitoring\n",
    "\n",
    "```\n",
    "Client  -->  FastAPI (8000)\n",
    "                 |\n",
    "                 +-->  Neon Postgres (cloud)\n",
    "                 |       +-- predictions (inputs JSONB, outputs, latence, timestamp)\n",
    "                 |       +-- drift_reports (metriques par fenetre temporelle)\n",
    "                 |       +-- api_logs (logs structures via Fluentd)\n",
    "                 |       +-- training_reference (stats de reference)\n",
    "                 |\n",
    "                 +-->  stdout (JSON structure)\n",
    "                 |       +-->  Fluentd --> Postgres (api_logs)\n",
    "                 |\n",
    "                 +-->  JSONL (backup local)\n",
    "\n",
    "Scripts batch :\n",
    "  simulate_production_traffic.py  -->  Envoie le test set par batches avec drift progressif\n",
    "  run_drift_detection.py         -->  Compare predictions recentes vs reference (training)\n",
    "\n",
    "Visualisation :\n",
    "  Grafana (3000)    -->  Dashboards SQL sur Postgres (logs, drift, latence)\n",
    "  Streamlit (8501)  -->  Dashboard interactif existant\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Connexion a la base de donnees de production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from monitoring.drift import compute_drift_report, simulate_drift\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "DATABASE_URL = os.environ.get(\"DATABASE_URL\", \"\")\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "print(f\"Base de donnees configuree : {'Oui' if DATABASE_URL else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion a Neon Postgres\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Vue d'ensemble des donnees de production\n",
    "stats = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        count(*) AS total_predictions,\n",
    "        min(created_at) AS premiere_prediction,\n",
    "        max(created_at) AS derniere_prediction,\n",
    "        round(avg(inference_time_ms)::numeric, 2) AS latence_moyenne_ms,\n",
    "        round(avg(probability)::numeric, 4) AS probabilite_moyenne,\n",
    "        round(avg(CASE WHEN decision = 'REFUSED' THEN 1.0 ELSE 0.0 END)::numeric * 100, 1) AS taux_refus_pct\n",
    "    FROM predictions\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"=== Donnees de production en base ===\")\n",
    "for col in stats.columns:\n",
    "    print(f\"  {col}: {stats[col].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-storage",
   "metadata": {},
   "source": [
    "### Que stocke-t-on ?\n",
    "\n",
    "Chaque appel a l'endpoint `/predict` de l'API enregistre dans la table `predictions` :\n",
    "\n",
    "| Colonne | Description | Pourquoi |\n",
    "|---------|------------|----------|\n",
    "| `sk_id_curr` | Identifiant du client | Tracabilite |\n",
    "| `features` | 419 features en JSONB | Detection de drift (inputs) |\n",
    "| `probability` | Score de defaut predit | Monitoring des outputs |\n",
    "| `decision` | APPROVED / REFUSED | Suivi des decisions |\n",
    "| `inference_time_ms` | Temps d'inference | Detection d'anomalies operationnelles |\n",
    "| `created_at` | Timestamp | Dimension temporelle pour le drift |\n",
    "\n",
    "C'est le `created_at` qui nous donne la **dimension temporelle** : en regroupant les predictions par fenetre de temps, on peut observer l'evolution de la distribution des features et detecter le drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Extraction et analyse des features de production\n",
    "\n",
    "Chaque prediction stockee contient les 419 features envoyees a l'API en format JSONB. On les extrait pour les comparer a la reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les predictions avec leurs features depuis Postgres\n",
    "prod_raw = pd.read_sql(\"\"\"\n",
    "    SELECT features, probability, decision, inference_time_ms, created_at\n",
    "    FROM predictions\n",
    "    WHERE features IS NOT NULL\n",
    "    ORDER BY created_at\n",
    "\"\"\", conn)\n",
    "\n",
    "print(f\"Predictions recuperees : {len(prod_raw)}\")\n",
    "\n",
    "# Extraire les features JSONB en colonnes pandas\n",
    "prod_features = pd.json_normalize(prod_raw[\"features\"])\n",
    "prod_features.index = prod_raw.index\n",
    "\n",
    "print(f\"Features extraites : {prod_features.shape[1]} colonnes\")\n",
    "print(f\"\\nApercu :\")\n",
    "prod_features.iloc[:3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnees de reference (echantillon du training data)\n",
    "reference = pd.read_csv(DATA_DIR / \"train_preprocessed.csv\", nrows=5000)\n",
    "drop_cols = [c for c in [\"SK_ID_CURR\", \"TARGET\"] if c in reference.columns]\n",
    "reference = reference.drop(columns=drop_cols)\n",
    "\n",
    "# Aligner les colonnes entre reference et production\n",
    "common_cols = sorted(set(reference.columns) & set(prod_features.columns))\n",
    "reference = reference[common_cols]\n",
    "prod_aligned = prod_features[common_cols]\n",
    "\n",
    "print(f\"Reference (training data) : {reference.shape[0]} lignes, {reference.shape[1]} features\")\n",
    "print(f\"Production (predictions)  : {prod_aligned.shape[0]} lignes, {prod_aligned.shape[1]} features\")\n",
    "print(f\"\\nLes features sont alignees : on peut comparer les distributions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Detection de drift : Reference vs Production\n",
    "\n",
    "On compare la distribution des features d'entrainement (reference) avec celles recues en production via le **test de Kolmogorov-Smirnov** (KS).\n",
    "\n",
    "- **KS statistic** : mesure la distance maximale entre les deux distributions (0 = identiques, 1 = completement differentes)\n",
    "- **p-value < 0.05** : on rejette l'hypothese que les deux distributions sont identiques → drift detecte\n",
    "\n",
    "Le module `monitoring/drift.py` (fonction `compute_drift_report`) encapsule cette logique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ks-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS test sur les top 30 features (reutilise monitoring/drift.py)\n",
    "drift_report = compute_drift_report(reference, prod_aligned, top_n=30)\n",
    "\n",
    "n_analyzed = len(drift_report)\n",
    "n_drifted = int(drift_report[\"drift_detected\"].sum())\n",
    "drift_pct = n_drifted / n_analyzed * 100\n",
    "\n",
    "# Determiner le status\n",
    "if drift_pct > 30:\n",
    "    status = \"ALERT\"\n",
    "elif drift_pct > 10:\n",
    "    status = \"WARNING\"\n",
    "else:\n",
    "    status = \"OK\"\n",
    "\n",
    "print(f\"=== Resultats de la detection de drift ===\")\n",
    "print(f\"Features analysees : {n_analyzed}\")\n",
    "print(f\"Features en drift  : {n_drifted} ({drift_pct:.1f}%)\")\n",
    "print(f\"Status             : {status}\")\n",
    "print(f\"\")\n",
    "print(f\"Rappel des seuils :\")\n",
    "print(f\"  < 10%  → OK (surveillance normale)\")\n",
    "print(f\"  10-30% → WARNING (investigation necessaire)\")\n",
    "print(f\"  > 30%  → ALERT (envisager un re-entrainement)\")\n",
    "print(f\"\\nTop 15 features par KS statistic :\")\n",
    "drift_report.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des KS statistics\n",
    "top_20 = drift_report.head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = ['#D32F2F' if d else '#388E3C' for d in top_20['drift_detected']]\n",
    "ax.barh(range(len(top_20)), top_20['ks_statistic'], color=colors)\n",
    "ax.set_yticks(range(len(top_20)))\n",
    "ax.set_yticklabels([f[:35] for f in top_20['feature']], fontsize=9)\n",
    "ax.set_xlabel('KS Statistic')\n",
    "ax.set_title('Top 20 Features — Test KS (Reference vs Production)', fontweight='bold', fontsize=13)\n",
    "ax.axvline(x=0.1, color='orange', linestyle='--', alpha=0.7, label='Seuil modere')\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Rouge = drift detecte (p-value < 0.05), Vert = pas de drift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-drift",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Le drift detecte ici est **attendu et voulu** : notre script de simulation `simulate_production_traffic.py` a envoye 8 batches de predictions a l'API :\n",
    "\n",
    "- **Batch 1-3** : donnees propres du test set (pas de drift)\n",
    "- **Batch 4-6** : drift graduel avec intensite croissante (0.1, 0.2, 0.3)\n",
    "- **Batch 7-8** : drift soudain avec forte intensite (0.5, 0.7)\n",
    "\n",
    "Comme on analyse toutes les predictions ensemble (y compris les batches driftes), le drift global est eleve. En production reelle, on analyserait par **fenetre temporelle** (ex: les predictions des dernieres 24h) pour detecter le drift au moment ou il apparait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evidently-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Rapport Evidently AI\n",
    "\n",
    "Evidently AI genere un rapport interactif detaille comparant les distributions feature par feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evidently-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset\n",
    "\n",
    "# Rapport Evidently : reference (training) vs production (predictions recentes)\n",
    "ev_report = Report([DataDriftPreset()])\n",
    "snapshot = ev_report.run(reference, prod_aligned)\n",
    "\n",
    "# Sauvegarder en HTML\n",
    "report_path = Path(\"../monitoring/drift_report_evidently.html\")\n",
    "snapshot.save_html(str(report_path))\n",
    "print(f\"Rapport Evidently sauvegarde : {report_path}\")\n",
    "\n",
    "# Afficher dans le notebook\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributions-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Distributions comparees — Features critiques du modele\n",
    "\n",
    "Toutes les features n'ont pas la meme importance. Les **top features** (celles qui influencent le plus les predictions du modele LightGBM) meritent une surveillance prioritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features du modele par importance\n",
    "model = joblib.load(ARTIFACTS_DIR / \"model.pkl\")\n",
    "with open(ARTIFACTS_DIR / \"feature_names.json\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "importances = sorted(\n",
    "    zip(feature_names, model.feature_importances_),\n",
    "    key=lambda x: x[1], reverse=True\n",
    ")\n",
    "top_features = [name for name, _ in importances[:6] if name in common_cols]\n",
    "\n",
    "print(\"Top 10 features du modele (par importance) :\\n\")\n",
    "for i, (name, imp) in enumerate(importances[:10], 1):\n",
    "    flag = \" <-- critique\" if i <= 3 else \"\"\n",
    "    print(f\"  {i:2d}. {name:<35s} importance = {imp}{flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions comparees : reference (vert) vs production (rouge)\n",
    "n_plots = min(6, len(top_features))\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(top_features[:n_plots]):\n",
    "    ax = axes[i]\n",
    "    ax.hist(reference[feat].dropna(), bins=50, alpha=0.6, label='Reference (train)',\n",
    "            color='#1D6A4B', density=True)\n",
    "    ax.hist(prod_aligned[feat].dropna(), bins=50, alpha=0.6, label='Production',\n",
    "            color='#8B2D2D', density=True)\n",
    "    \n",
    "    # Ajouter la KS stat\n",
    "    ks_row = drift_report[drift_report['feature'] == feat]\n",
    "    ks_val = f\"{ks_row['ks_statistic'].iloc[0]:.3f}\" if len(ks_row) > 0 else 'N/A'\n",
    "    ax.set_title(f\"{feat}\\nKS = {ks_val}\", fontsize=10, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "for j in range(n_plots, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions comparees — Top Features (Reference vs Production)',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Analyse operationnelle\n",
    "\n",
    "Au-dela du drift sur les features, le cahier des charges demande de detecter des **problemes operationnels** : taux d'erreur et latence anormale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriques operationnelles\n",
    "operational = pd.read_sql(\"\"\"\n",
    "    SELECT probability, decision, inference_time_ms, created_at\n",
    "    FROM predictions\n",
    "    ORDER BY created_at\n",
    "\"\"\", conn)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# 1. Latence au fil du temps\n",
    "axes[0].plot(range(len(operational)), operational['inference_time_ms'],\n",
    "             alpha=0.5, linewidth=0.8, color='#1B2A4A')\n",
    "p95 = operational['inference_time_ms'].quantile(0.95)\n",
    "axes[0].axhline(y=p95, color='red', linestyle='--', label=f'P95 = {p95:.1f} ms')\n",
    "axes[0].set_title('Latence d\\'inference (ms)', fontweight='bold')\n",
    "axes[0].set_xlabel('# prediction')\n",
    "axes[0].set_ylabel('ms')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. Distribution des scores\n",
    "approved = operational[operational['decision'] == 'APPROVED']['probability']\n",
    "refused = operational[operational['decision'] == 'REFUSED']['probability']\n",
    "axes[1].hist(approved, bins=30, alpha=0.7, label='APPROVED', color='#388E3C')\n",
    "axes[1].hist(refused, bins=30, alpha=0.7, label='REFUSED', color='#D32F2F')\n",
    "axes[1].axvline(x=0.494, color='black', linestyle='--', label='Seuil (0.494)')\n",
    "axes[1].set_title('Distribution des scores', fontweight='bold')\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "# 3. Repartition des decisions\n",
    "decision_counts = operational['decision'].value_counts()\n",
    "colors = ['#388E3C' if d == 'APPROVED' else '#D32F2F' for d in decision_counts.index]\n",
    "axes[2].pie(decision_counts, labels=decision_counts.index,\n",
    "            autopct='%1.1f%%', colors=colors)\n",
    "axes[2].set_title('Repartition des decisions', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Metriques operationnelles :\")\n",
    "print(f\"  Latence moyenne : {operational['inference_time_ms'].mean():.2f} ms\")\n",
    "print(f\"  Latence P50     : {operational['inference_time_ms'].median():.2f} ms\")\n",
    "print(f\"  Latence P95     : {p95:.2f} ms\")\n",
    "print(f\"  Latence max     : {operational['inference_time_ms'].max():.2f} ms\")\n",
    "print(f\"  Taux de refus   : {(operational['decision'] == 'REFUSED').mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift-history-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Historique des rapports de drift\n",
    "\n",
    "Les rapports de drift sont stockes dans la table `drift_reports` de Postgres. Le script `run_drift_detection.py` les genere automatiquement en comparant les predictions recentes contre la reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historique des rapports de drift\n",
    "drift_history = pd.read_sql(\"\"\"\n",
    "    SELECT report_date, n_predictions, n_features_analyzed,\n",
    "           n_features_drifted, drift_percentage, status\n",
    "    FROM drift_reports\n",
    "    ORDER BY report_date\n",
    "\"\"\", conn)\n",
    "\n",
    "if len(drift_history) > 0:\n",
    "    print(f\"Rapports de drift en base : {len(drift_history)}\")\n",
    "    display(drift_history)\n",
    "else:\n",
    "    print(\"Aucun rapport de drift encore. Executez :\")\n",
    "    print(\"  DATABASE_URL=... python scripts/run_drift_detection.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-ref-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Statistiques de reference (training data)\n",
    "\n",
    "Les stats descriptives du training data sont pre-calculees et stockees dans la table `training_reference`. Cela permet au script de drift detection de comparer sans recharger le CSV complet a chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-ref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats de reference stockees en base\n",
    "ref_stats = pd.read_sql(\"\"\"\n",
    "    SELECT feature_name, mean, std, median, q25, q75, n_samples\n",
    "    FROM training_reference\n",
    "    ORDER BY feature_name\n",
    "    LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "print(f\"Features de reference en base : {pd.read_sql('SELECT count(*) FROM training_reference', conn).iloc[0, 0]}\")\n",
    "print(f\"\\nApercu (10 premieres) :\")\n",
    "ref_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simulation-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Comment reproduire cette analyse\n",
    "\n",
    "### Etape 1 : Initialiser la base\n",
    "```bash\n",
    "DATABASE_URL=... python scripts/init_db.py\n",
    "```\n",
    "Cree les tables et insere les stats de reference du training data.\n",
    "\n",
    "### Etape 2 : Lancer l'API\n",
    "```bash\n",
    "DATABASE_URL=... uvicorn api.app:app --port 8000\n",
    "```\n",
    "L'API stocke maintenant chaque prediction dans Postgres.\n",
    "\n",
    "### Etape 3 : Simuler du trafic avec drift\n",
    "```bash\n",
    "python scripts/simulate_production_traffic.py --batch-size 50 --n-batches 8 --delay 2\n",
    "```\n",
    "Envoie 400 predictions avec drift progressif :\n",
    "- Batch 1-3 : donnees propres\n",
    "- Batch 4-6 : drift graduel (intensite 0.1 → 0.3)\n",
    "- Batch 7-8 : drift soudain (intensite 0.5 → 0.7)\n",
    "\n",
    "### Etape 4 : Analyser le drift\n",
    "```bash\n",
    "DATABASE_URL=... python scripts/run_drift_detection.py\n",
    "```\n",
    "Compare les predictions recentes vs la reference et stocke le rapport dans `drift_reports`.\n",
    "\n",
    "### Etape 5 : Visualiser\n",
    "```bash\n",
    "docker compose up  # Lance API + Dashboard + Fluentd + Grafana\n",
    "```\n",
    "- **Grafana** : http://localhost:3000 (admin/admin)\n",
    "- **Streamlit** : http://localhost:8501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recommendations",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Points de vigilance et recommandations\n",
    "\n",
    "### Resultats cles\n",
    "\n",
    "| Aspect | Constat |\n",
    "|--------|--------|\n",
    "| **Stockage** | Chaque prediction stockee avec inputs (419 features JSONB), outputs, latence, timestamp |\n",
    "| **Drift temporel** | Le timestamp des predictions permet une analyse par fenetre temporelle |\n",
    "| **Features critiques** | EXT_SOURCE_*, AMT_CREDIT, DAYS_BIRTH doivent etre monitorees en priorite |\n",
    "| **Detection** | Le drift simule est correctement detecte, proportionnellement a l'intensite |\n",
    "\n",
    "### Seuils d'alerte\n",
    "\n",
    "| Drift % | Status | Action |\n",
    "|---------|--------|--------|\n",
    "| < 10% | OK | Surveillance normale |\n",
    "| 10-30% | WARNING | Investigation necessaire |\n",
    "| > 30% | ALERT | Envisager un re-entrainement |\n",
    "\n",
    "### Stack de monitoring\n",
    "\n",
    "| Composant | Role |\n",
    "|-----------|------|\n",
    "| **Neon Postgres** | Stockage : predictions, drift_reports, api_logs, training_reference |\n",
    "| **Fluentd** | Collecte des logs API structures → Postgres |\n",
    "| **Evidently AI** | Rapports de drift detailles (KS test, distributions) |\n",
    "| **Grafana** | Dashboards temps reel : latence, volume, drift |\n",
    "| **Streamlit** | Dashboard interactif existant |\n",
    "\n",
    "### Limites\n",
    "\n",
    "- **Drift != degradation** : un drift statistique ne signifie pas forcement que le modele performe moins bien. Les deux doivent etre surveilles conjointement.\n",
    "- **Drift simule vs reel** : nos simulations sont artificielles. En production, le drift est souvent plus subtil et multidimensionnel.\n",
    "- **Pas de concept drift** : le test set Kaggle n'a pas de TARGET, donc on ne peut mesurer que le data drift, pas l'impact sur la performance du modele.\n",
    "- **Conformite RGPD** : les features sont anonymisees, les rapports analysent des distributions statistiques, pas des donnees individuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"Analyse terminee.\")\n",
    "print(\"\\nFichiers generes :\")\n",
    "print(\"  - monitoring/drift_report_evidently.html\")\n",
    "print(\"\\nTables Postgres :\")\n",
    "print(\"  - predictions  (inputs, outputs, latence, timestamp)\")\n",
    "print(\"  - drift_reports (rapports par fenetre temporelle)\")\n",
    "print(\"  - training_reference (stats de reference du training data)\")\n",
    "print(\"  - api_logs (logs structures via Fluentd)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
