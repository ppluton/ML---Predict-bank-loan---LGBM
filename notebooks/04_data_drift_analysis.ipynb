{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Analyse du Data Drift — Credit Scoring\n",
    "\n",
    "Ce notebook réalise l'analyse de la **dérive des données (data drift)** pour notre modèle de scoring crédit déployé en production.\n",
    "\n",
    "**Approche :**\n",
    "\n",
    "- **Référence** : distribution des données d'entraînement (stockée dans Postgres)\n",
    "- **Production** : features envoyées à l'API pour chaque prédiction, horodatées et stockées dans Neon Postgres\n",
    "- **Détection** : comparaison par fenêtre temporelle (KS test + Evidently AI)\n",
    "- **Simulation** : le script `simulate_production_traffic.py` envoie des batches avec drift progressif\n",
    "\n",
    "### Pourquoi pas train vs test ?\n",
    "\n",
    "Comparer `train_preprocessed.csv` vs `test_preprocessed.csv` ne détecte pas du vrai drift car les deux proviennent du même dataset Kaggle. En production, le drift est **temporel** : la distribution des données évolue au fil du temps. Notre API horodate chaque prédiction — c'est cette dimension temporelle qu'on exploite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Rappel : qu'est-ce que le Data Drift ?\n",
    "\n",
    "Un modèle ML est entraîné sur des données historiques. En production, si les nouvelles données ont des **distributions différentes**, le modèle risque de perdre en fiabilité.\n",
    "\n",
    "| Type              | Description                      | Exemple                                         |\n",
    "| ----------------- | -------------------------------- | ----------------------------------------------- |\n",
    "| **Drift graduel** | Distributions changent lentement | Inflation sur les montants de crédit            |\n",
    "| **Drift soudain** | Changement brutal                | Nouveau segment de clientèle, crise             |\n",
    "| **Feature shift** | Variables spécifiques changent   | Fournisseur de score externe modifie son calcul |\n",
    "\n",
    "**Détection** : on compare la distribution de **référence** (entraînement) avec la distribution de **production** (prédictions récentes) via le test de Kolmogorov-Smirnov (KS). Si p-value < 0.05 → drift détecté.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Connexion à la base de données de production\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from monitoring.drift import compute_drift_report, simulate_drift\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "DATABASE_URL = os.environ.get(\"DATABASE_URL\", \"\")\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "print(f\"DB connectée : {'Oui' if DATABASE_URL else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à Neon Postgres\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Vérifier les données disponibles\n",
    "stats = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        count(*) AS total_predictions,\n",
    "        min(created_at) AS first_prediction,\n",
    "        max(created_at) AS last_prediction,\n",
    "        avg(inference_time_ms) AS avg_latency_ms,\n",
    "        avg(probability) AS avg_probability\n",
    "    FROM predictions\n",
    "\"\"\",\n",
    "    conn,\n",
    ")\n",
    "\n",
    "print(\"=== Données de production en base ===\")\n",
    "print(f\"Total prédictions : {stats['total_predictions'].iloc[0]}\")\n",
    "print(f\"Première : {stats['first_prediction'].iloc[0]}\")\n",
    "print(f\"Dernière : {stats['last_prediction'].iloc[0]}\")\n",
    "print(f\"Latence moyenne : {stats['avg_latency_ms'].iloc[0]:.2f} ms\")\n",
    "print(f\"Probabilité moyenne : {stats['avg_probability'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "production-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Extraction des features de production\n",
    "\n",
    "Chaque prédiction stockée en base contient les **419 features** envoyées à l'API (en JSONB), horodatées. On les extrait pour les comparer à la référence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les prédictions avec leurs features depuis Postgres\n",
    "prod_raw = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT features, probability, decision, inference_time_ms, created_at\n",
    "    FROM predictions\n",
    "    WHERE features IS NOT NULL\n",
    "    ORDER BY created_at\n",
    "\"\"\",\n",
    "    conn,\n",
    ")\n",
    "\n",
    "print(f\"Prédictions récupérées : {len(prod_raw)}\")\n",
    "\n",
    "# Extraire les features JSONB en colonnes\n",
    "prod_features = pd.json_normalize(prod_raw[\"features\"])\n",
    "prod_features.index = prod_raw.index\n",
    "\n",
    "print(f\"Features extraites : {prod_features.shape[1]} colonnes\")\n",
    "prod_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de référence (training data)\n",
    "reference = pd.read_csv(DATA_DIR / \"train_preprocessed.csv\", nrows=5000)\n",
    "drop_cols = [c for c in [\"SK_ID_CURR\", \"TARGET\"] if c in reference.columns]\n",
    "reference = reference.drop(columns=drop_cols)\n",
    "\n",
    "# Aligner les colonnes\n",
    "common_cols = sorted(set(reference.columns) & set(prod_features.columns))\n",
    "reference = reference[common_cols]\n",
    "prod_aligned = prod_features[common_cols]\n",
    "\n",
    "print(f\"Référence : {reference.shape[0]} lignes, {reference.shape[1]} features\")\n",
    "print(f\"Production : {prod_aligned.shape[0]} lignes, {prod_aligned.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift-detection-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Détection de drift : Référence vs Production\n",
    "\n",
    "On compare la distribution des features d'entraînement (référence) avec celles reçues en production via le **test de Kolmogorov-Smirnov**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ks-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS test sur toutes les features (réutilise monitoring/drift.py)\n",
    "drift_report = compute_drift_report(reference, prod_aligned, top_n=30)\n",
    "\n",
    "n_analyzed = len(drift_report)\n",
    "n_drifted = drift_report[\"drift_detected\"].sum()\n",
    "drift_pct = n_drifted / n_analyzed * 100\n",
    "\n",
    "print(f\"Features analysées : {n_analyzed}\")\n",
    "print(f\"Features en drift : {n_drifted} ({drift_pct:.1f}%)\")\n",
    "print(\n",
    "    f\"\\nStatus : {'ALERT' if drift_pct > 30 else 'WARNING' if drift_pct > 10 else 'OK'}\"\n",
    ")\n",
    "print(f\"\\nTop 15 features par drift (KS statistic) :\")\n",
    "drift_report.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les KS statistics\n",
    "top_20 = drift_report.head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = [\"#D32F2F\" if d else \"#388E3C\" for d in top_20[\"drift_detected\"]]\n",
    "bars = ax.barh(range(len(top_20)), top_20[\"ks_statistic\"], color=colors)\n",
    "ax.set_yticks(range(len(top_20)))\n",
    "ax.set_yticklabels([f[:30] for f in top_20[\"feature\"]], fontsize=9)\n",
    "ax.set_xlabel(\"KS Statistic\")\n",
    "ax.set_title(\"Top 20 Features — KS Test (Référence vs Production)\", fontweight=\"bold\")\n",
    "ax.axvline(x=0.1, color=\"orange\", linestyle=\"--\", alpha=0.7, label=\"Seuil modéré\")\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evidently-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Rapport Evidently AI\n",
    "\n",
    "Evidently AI génère un rapport interactif complet comparant les distributions de chaque feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evidently-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport Evidently : référence vs production\n",
    "ev_report = Report([DataDriftPreset()])\n",
    "snapshot = ev_report.run(reference, prod_aligned)\n",
    "\n",
    "# Sauvegarder en HTML\n",
    "report_path = Path(\"../monitoring/drift_report_evidently.html\")\n",
    "snapshot.save_html(str(report_path))\n",
    "print(f\"Rapport Evidently sauvegardé : {report_path}\")\n",
    "\n",
    "# Afficher dans le notebook\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributions-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Distributions comparées — Features critiques\n",
    "\n",
    "Visualisons les distributions des features les plus importantes du modèle entre la référence et la production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features du modèle par importance\n",
    "model = joblib.load(ARTIFACTS_DIR / \"model.pkl\")\n",
    "with open(ARTIFACTS_DIR / \"feature_names.json\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "importances = sorted(\n",
    "    zip(feature_names, model.feature_importances_), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "top_features = [name for name, _ in importances[:6] if name in common_cols]\n",
    "\n",
    "print(\"Top features du modèle :\")\n",
    "for i, (name, imp) in enumerate(importances[:10], 1):\n",
    "    print(f\"  {i:2d}. {name:<35s} importance = {imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions comparées\n",
    "n_plots = min(6, len(top_features))\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(top_features[:n_plots]):\n",
    "    ax = axes[i]\n",
    "    ax.hist(\n",
    "        reference[feat].dropna(),\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=\"Référence (train)\",\n",
    "        color=\"#1D6A4B\",\n",
    "        density=True,\n",
    "    )\n",
    "    ax.hist(\n",
    "        prod_aligned[feat].dropna(),\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=\"Production\",\n",
    "        color=\"#8B2D2D\",\n",
    "        density=True,\n",
    "    )\n",
    "\n",
    "    # KS stat pour cette feature\n",
    "    ks_row = drift_report[drift_report[\"feature\"] == feat]\n",
    "    ks_val = ks_row[\"ks_statistic\"].iloc[0] if len(ks_row) > 0 else \"N/A\"\n",
    "    ax.set_title(f\"{feat}\\nKS = {ks_val}\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Masquer les axes vides\n",
    "for j in range(n_plots, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Distributions comparées — Top Features (Référence vs Production)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift-reports-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Historique des rapports de drift\n",
    "\n",
    "Les rapports de drift sont stockés dans la table `drift_reports` de Postgres, permettant de suivre l'évolution du drift au fil du temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger l'historique des rapports de drift\n",
    "drift_history = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT report_date, n_predictions, n_features_analyzed,\n",
    "           n_features_drifted, drift_percentage, status\n",
    "    FROM drift_reports\n",
    "    ORDER BY report_date\n",
    "\"\"\",\n",
    "    conn,\n",
    ")\n",
    "\n",
    "print(f\"Rapports de drift en base : {len(drift_history)}\")\n",
    "drift_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse opérationnelle : latence et distribution des scores\n",
    "operational = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        created_at,\n",
    "        probability,\n",
    "        decision,\n",
    "        inference_time_ms\n",
    "    FROM predictions\n",
    "    ORDER BY created_at\n",
    "\"\"\",\n",
    "    conn,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Latence au fil du temps\n",
    "axes[0].plot(\n",
    "    operational[\"created_at\"],\n",
    "    operational[\"inference_time_ms\"],\n",
    "    alpha=0.5,\n",
    "    linewidth=0.5,\n",
    "    color=\"#1B2A4A\",\n",
    ")\n",
    "axes[0].axhline(\n",
    "    y=operational[\"inference_time_ms\"].quantile(0.95),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"P95\",\n",
    ")\n",
    "axes[0].set_title(\"Latence d'inférence (ms)\", fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"ms\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Distribution des scores\n",
    "approved = operational[operational[\"decision\"] == \"APPROVED\"][\"probability\"]\n",
    "refused = operational[operational[\"decision\"] == \"REFUSED\"][\"probability\"]\n",
    "axes[1].hist(approved, bins=30, alpha=0.7, label=\"APPROVED\", color=\"#388E3C\")\n",
    "axes[1].hist(refused, bins=30, alpha=0.7, label=\"REFUSED\", color=\"#D32F2F\")\n",
    "axes[1].axvline(x=0.494, color=\"black\", linestyle=\"--\", label=\"Seuil (0.494)\")\n",
    "axes[1].set_title(\"Distribution des scores\", fontweight=\"bold\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Répartition des décisions\n",
    "decision_counts = operational[\"decision\"].value_counts()\n",
    "axes[2].pie(\n",
    "    decision_counts,\n",
    "    labels=decision_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[\"#388E3C\", \"#D32F2F\"],\n",
    ")\n",
    "axes[2].set_title(\"Répartition des décisions\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMétriques opérationnelles :\")\n",
    "print(f\"  Latence moyenne : {operational['inference_time_ms'].mean():.2f} ms\")\n",
    "print(f\"  Latence P95 : {operational['inference_time_ms'].quantile(0.95):.2f} ms\")\n",
    "print(f\"  Taux de refus : {(operational['decision'] == 'REFUSED').mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simulation-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Simulation de drift et scripts de production\n",
    "\n",
    "### Pipeline de monitoring en production\n",
    "\n",
    "```\n",
    "1. simulate_production_traffic.py  →  Envoie des batches à l'API avec drift progressif\n",
    "   - Batch 1-3 : données propres (pas de drift)\n",
    "   - Batch 4-6 : drift graduel (intensité 0.1, 0.2, 0.3)\n",
    "   - Batch 7-8 : drift soudain (intensité 0.5, 0.7)\n",
    "\n",
    "2. L'API stocke chaque prédiction + features dans Postgres (table predictions)\n",
    "\n",
    "3. run_drift_detection.py  →  Compare les prédictions récentes vs référence\n",
    "   - Fenêtre temporelle configurable (défaut: 24h)\n",
    "   - KS test sur les top features\n",
    "   - Résultat stocké dans drift_reports\n",
    "\n",
    "4. Grafana / Streamlit  →  Visualisation temps réel\n",
    "```\n",
    "\n",
    "### Comment exécuter :\n",
    "\n",
    "```bash\n",
    "# 1. Lancer l'API\n",
    "DATABASE_URL=... uvicorn api.app:app --port 8000\n",
    "\n",
    "# 2. Simuler du trafic avec drift\n",
    "python scripts/simulate_production_traffic.py --batch-size 50 --n-batches 8\n",
    "\n",
    "# 3. Analyser le drift\n",
    "DATABASE_URL=... python scripts/run_drift_detection.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recommendations",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Points de vigilance et recommandations\n",
    "\n",
    "### Résultats de l'analyse\n",
    "\n",
    "| Aspect                 | Constat                                                                                 |\n",
    "| ---------------------- | --------------------------------------------------------------------------------------- |\n",
    "| **Stockage**           | Chaque prédiction stockée avec inputs (419 features JSONB), outputs, latence, timestamp |\n",
    "| **Drift temporel**     | Le timestamp des prédictions permet une analyse par fenêtre temporelle                  |\n",
    "| **Features critiques** | EXT*SOURCE*\\*, AMT_CREDIT, DAYS_BIRTH doivent être monitorées en priorité               |\n",
    "| **Simulation**         | Le drift simulé est correctement détecté, proportionnellement à l'intensité             |\n",
    "\n",
    "### Seuils d'alerte\n",
    "\n",
    "| Drift % | Status  | Action                       |\n",
    "| ------- | ------- | ---------------------------- |\n",
    "| < 10%   | OK      | Surveillance normale         |\n",
    "| 10-30%  | WARNING | Investigation nécessaire     |\n",
    "| > 30%   | ALERT   | Envisager un ré-entraînement |\n",
    "\n",
    "### Architecture de monitoring\n",
    "\n",
    "| Composant         | Rôle                                                                |\n",
    "| ----------------- | ------------------------------------------------------------------- |\n",
    "| **Neon Postgres** | Stockage : predictions, drift_reports, api_logs, training_reference |\n",
    "| **Fluentd**       | Collecte des logs API structurés → Postgres                         |\n",
    "| **Evidently AI**  | Rapports de drift détaillés (KS test, distributions)                |\n",
    "| **Grafana**       | Dashboards : latence, volume, drift au fil du temps                 |\n",
    "| **Streamlit**     | Dashboard interactif existant                                       |\n",
    "\n",
    "### Limites\n",
    "\n",
    "- **Drift ≠ dégradation** : un drift statistique ne signifie pas forcément que le modèle performe moins bien\n",
    "- **Drift simulé vs réel** : nos simulations sont artificielles ; en production le drift est plus subtil\n",
    "- **Pas de concept drift** : le test set Kaggle n'a pas de TARGET, donc on ne peut mesurer que le data drift, pas l'impact sur la performance\n",
    "- **Conformité RGPD** : les features sont anonymisées, les rapports analysent des distributions statistiques (pas de données individuelles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"Analyse de drift terminée.\")\n",
    "print(\"\\nFichiers générés :\")\n",
    "print(\"  - monitoring/drift_report_evidently.html (rapport Evidently interactif)\")\n",
    "print(\"\\nTables Postgres utilisées :\")\n",
    "print(\"  - predictions (inputs, outputs, latence, timestamp)\")\n",
    "print(\"  - drift_reports (rapports par fenêtre temporelle)\")\n",
    "print(\"  - training_reference (stats de référence)\")\n",
    "print(\"  - api_logs (logs structurés via Fluentd)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
