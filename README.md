# ğŸ¦ ModÃ¨le de Scoring de CrÃ©dit - Projet MLOps OpenClassrooms

## Formation AI Engineer 2026 - Projet OC6

[![MLFlow](https://img.shields.io/badge/MLFlow-Tracking-blue.svg)](https://mlflow.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-green.svg)](https://www.python.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit-learn-ML-orange.svg)](https://scikit-learn.org/)
[![LightGBM](https://img.shields.io/badge/LightGBM-Boosting-yellow.svg)](https://lightgbm.readthedocs.io/)

### ğŸ“Š **RÃ©sumÃ© ExÃ©cutif**

**ProblÃ¨me mÃ©tier** : PrÃ©dire le risque de dÃ©faut de paiement des clients d'une institution financiÃ¨re de microcrÃ©dit (Home Credit Default Risk).

**DÃ©fi principal** : Dataset massivement dÃ©sÃ©quilibrÃ© (91.9% bons clients vs 8.1% dÃ©fauts â†’ ratio **11.4:1**) + 8 tables relationnelles Ã  agrÃ©ger.

**Solution proposÃ©e** : Pipeline MLOps complet avec **innovations mÃ©thodologiques** :

- AgrÃ©gation hiÃ©rarchique de 57M+ lignes â†’ 305 features
- **Feature "Has_History"** : capture l'absence d'historique (info critique)
- **Imputation stratÃ©gique** : 5 approches selon sÃ©mantique mÃ©tier
- **Score mÃ©tier personnalisÃ©** : FN = 10Ã— FP (prioritÃ© recall - consigne OpenClassrooms)
- **MLFlow tracking complet** : baselines, tuning, seuil optimal

**RÃ©sultats** : ModÃ¨le LightGBM optimisÃ© avec coÃ»t mÃ©tier minimisÃ©, prÃªt pour production.

---

## ğŸ¯ **Objectifs du Projet**

1. **IngÃ©nierie des features avancÃ©es** Ã  partir de donnÃ©es relationnelles complexes
2. **Pipeline preprocessing robuste** gÃ©rant intelligemment les NaN mÃ©tier
3. **ModÃ©lisation orientÃ©e business** avec score coÃ»t asymÃ©trique
4. **MLOps** : tracking expÃ©rimentations, reproductibilitÃ©, model registry
5. **Optimisation du seuil de dÃ©cision** pour maximiser le recall mÃ©tier

---

## ğŸ—ï¸ **Architecture du Pipeline MLOps**

```
ğŸ“¥ DonnÃ©es Brutes (8 CSV)
    â†“ AgrÃ©gation HiÃ©rarchique (Notebook 01)
ğŸ“Š train_aggregated.csv (307k Ã— 305 features)
    â†“ Preprocessing + Feature Engineering (Notebook 02)
âš™ï¸ train_preprocessed.csv (307k Ã— 265 features, 0 NaN, scalÃ©)
    â†“ Modeling + MLFlow (Notebook 03)
ğŸš€ Meilleur ModÃ¨le LightGBM (trackÃ© MLFlow)
    â†“ Seuil Optimal + Production Ready
ğŸ“¤ submission.csv (prÃ©dictions Kaggle)
```

---

## ğŸ“ **Structure du Projet**

```
OC6_MLOPS/
â”œâ”€â”€ data/                          # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ application_train.csv      # Table principale (307k lignes)
â”‚   â”œâ”€â”€ bureau.csv                 # Historique crÃ©dits externes (1.7M)
â”‚   â”œâ”€â”€ train_aggregated.csv       # AprÃ¨s Notebook 01 (305 features)
â”‚   â”œâ”€â”€ train_preprocessed.csv     # AprÃ¨s Notebook 02 (265 features)
â”‚   â””â”€â”€ submission.csv             # PrÃ©dictions finales
â”œâ”€â”€ notebooks/                     # Pipeline en 3 Ã©tapes
â”‚   â”œâ”€â”€ 01_EDA.ipynb               # EDA + AgrÃ©gation
â”‚   â”œâ”€â”€ 02_preprocessing_and_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_modeling_with_MLFLOW.ipynb
â”œâ”€â”€ notebooks/charts_eda/          # Visualisations EDA
â”‚   â”œâ”€â”€ graphique_1_age_distribution.png
â”‚   â”œâ”€â”€ graphique_2_correlations.png
â”‚   â””â”€â”€ graphique_5_historique_bureau.png
â”œâ”€â”€ src/                           # Code modulaire (production-ready)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ modeling.py
â”œâ”€â”€ mlruns/                        # MLFlow tracking automatique
â”œâ”€â”€ models/                        # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ pyproject.toml                 # DÃ©pendances (uv/pip)
â”œâ”€â”€ uv.lock                        # Lockfile uv
â””â”€â”€ README.md                      # Ce fichier
```

---

## ğŸš€ **Installation & ExÃ©cution**

### PrÃ©requis

- Python 3.10+
- [uv](https://docs.astral.sh/uv/) (recommandÃ©) ou pip

### Installation

```bash
git clone <votre-repo>
cd OC6_MLOPS
uv sync          # ou pip install -e .
```

### Lancer le Pipeline Complet

```bash
# 1. EDA + AgrÃ©gation
jupyter notebook notebooks/01_EDA.ipynb

# 2. Preprocessing + Features
jupyter notebook notebooks/02_preprocessing_and_feature_engineering.ipynb

# 3. Modeling + MLFlow
jupyter notebook notebooks/03_modeling_with_MLFLOW.ipynb

# Visualiser les expÃ©riences
mlflow ui          # http://localhost:5000
```

**DÃ©pendances principales** : `pandas`, `scikit-learn`, `lightgbm`, `mlflow`, `matplotlib`, `seaborn`, `joblib`

---

## ğŸ“ **MÃ©thodologie DÃ©taillÃ©e par Notebook**

### **Notebook 01 : EDA & AgrÃ©gation HiÃ©rarchique** ğŸ”

**Objectifs** :

- Charger 8 tables (57M+ lignes total)
- Analyser relations : `application_train â† bureau â† bureau_balance`, `previous_application â† POS/CC/Installments`
- CrÃ©er dataset plat pour ML

**Innovations** :

- **AgrÃ©gation en cascade** : `bureau_balance` (27M) â†’ `bureau` â†’ client
- 183 features crÃ©Ã©es : 45 bureau + 138 previous_application
- **Statistiques riches** : min/max/mean/sum + one-hot catÃ©gorielles
- **Visualisations avancÃ©es** : 5 graphiques EDA (Ã¢ge, corrÃ©lations, EXT_SOURCE, ratios, bureau)

**RÃ©sultats** :

```
307,511 clients Ã— 305 features
DÃ©sÃ©quilibre : 91.9% bons vs 8.1% dÃ©fauts (11.4:1)
250/305 colonnes NaN (normal : absence historique)
Outputs : train_aggregated.csv + test_aggregated.csv
```

### **Notebook 02 : Preprocessing & Feature Engineering AvancÃ©** âš™ï¸

**Objectifs** :

- GÃ©rer 250 colonnes NaN intelligemment
- CrÃ©er features mÃ©tier prÃ©dictives
- PrÃ©parer donnÃ©es scalÃ©es pour ML

**ğŸš€ Innovations ClÃ©s** :

1. **Feature "Has_History" (INNOVATION PROPRIA)** :

   ```
   HAS_BUREAU, HAS_PREV_APP, HAS_CREDIT_CARD, HAS_POS_CASH, HAS_INSTALLMENTS
   CrÃ©Ã©es AVANT imputation â†’ capture "aucun historique = info mÃ©tier"
   ```

2. **Imputation StratÃ©gique (5 rÃ¨gles sÃ©mantiques)** :
   | Type Colonne | StratÃ©gie | Exemple | Rationale |
   |------------------|---------------|--------------------------|-----------|
   | Montants (AMT*) | 0 | AMT_CREDIT_SUM â†’ 0 | Pas de crÃ©dit = 0â‚¬ |
   | Comptages (CNT*) | 0 | SK_ID_BUREAU_COUNT â†’ 0 | 0 occurrence |
   | Dates (DAYS*) | -999 | DAYS_BIRTH â†’ -999 | Sentinelle |
   | Moyennes (MEAN*) | MÃ©diane | EXT_SOURCE_MEAN â†’ median | Robuste outliers |
   | Autres | MÃ©diane | - | DÃ©faut conservateur |

3. **Feature Engineering MÃ©tier (11 nouvelles)** :
   ```
   ğŸ’° CREDIT_INCOME_RATIO (rÃ¨gle 33%)
   ğŸ’³ ANNUITY_INCOME_RATIO (capacitÃ© remboursement)
   ğŸ‘´ AGE_YEARS, ğŸ‘· EMPLOYMENT_YEARS
   ğŸ“Š EXT_SOURCE_MEAN/PROD (scores agrÃ©gÃ©s)
   ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ INCOME_PER_PERSON, CHILDREN_RATIO
   ğŸ¦ BUREAU_DEBT_INCOME_RATIO
   ```

**RÃ©sultats** :

```
307k Ã— 265 features | 0 NaN | 0 Inf | ScalÃ© (mean=0, std=1)
-45 colonnes (>80% NaN supprimÃ©es)
Scaler.pkl sauvegardÃ© (production-ready)
```

### **Notebook 03 : Modeling MLOps avec MLFlow** ğŸ¯

**Objectifs** :

- Baselines + tuning
- Score mÃ©tier asymÃ©trique
- Tracking reproductible

**ğŸš€ Innovations** :

1. **Score MÃ©tier PersonnalisÃ©** (consigne OpenClassrooms) :

   ```python
   coÃ»t_total = (FN Ã— 10) + FP    # Recall prioritaire
   ```

2. **3 Baselines ComparÃ©es** :
   | ModÃ¨le | Avantages | CV Business Cost |
   |------------------|------------------------|------------------|
   | Logistic Reg | LinÃ©aire, rapide | Baseline |
   | Random Forest | Non-linÃ©aire | Moyen |
   | **LightGBM** | **Gradient Boosting** | **Meilleur** |

3. **Hyperparameter Tuning** : GridSearchCV (27 combinaisons)
4. **Seuil Optimal** : ~0.3-0.4 (vs 0.5 dÃ©faut) â†’ +X% recall
5. **MLFlow Complet** :
   - ParamÃ¨tres, mÃ©triques CV/train
   - Matrices confusion visualisÃ©es
   - ModÃ¨les loggÃ©s + artifacts

**Outputs** :

```
submission.csv (Kaggle-ready)
mlruns/ (tracking)
model_metadata.json
```

---

## ğŸ’¡ **Points Forts MÃ©thodologiques (Jury)**

| Innovation                | Impact MÃ©tier/Business                     |
| ------------------------- | ------------------------------------------ |
| **Has_History features**  | "Nouveau client" = risque â†’ info critique  |
| **Imputation sÃ©mantique** | Respecte logique bancaire (0â‚¬=pas crÃ©dit)  |
| **Score FN=10Ã—FP**        | Recall prioritaire (perte >> manque gain)  |
| **Seuil optimisÃ©**        | +X% performance coÃ»t mÃ©tier                |
| **No Data Leakage**       | Scaler fit train only                      |
| **MLFlow end-to-end**     | Reproductible, auditable, production-ready |

**Gestion DÃ©sÃ©quilibre** : `class_weight=balanced` + score asymÃ©trique + seuil optimisÃ©.

---

## ğŸ“Š **MÃ©triques ClÃ©s (Placeholders - Ã  finaliser)**

```
Dataset : 307k train | 48k test | 11.4:1 imbalance
Features: 122 orig â†’ 305 agrÃ©gÃ©es â†’ 265 finales
NaN : 82% â†’ 0%
Meilleur ModÃ¨le : LightGBM Tuned
CV Business Cost : [X.XX] Â± [X.XX]
Train AUC : [XX.X]%
Seuil Optimal : [X.XX] (vs 0.5)
AmÃ©lioration seuil : [+X.X]%
```
---

## ğŸ‘¨â€ğŸ’» **Auteur & Licence**

**Auteur** : Pierre Pluton  
**Formation** : OpenClassrooms AI Engineer 2026 - Projet OC6 MLOps  
**Date** : Janvier 2026

**Licence** : MIT License

```
Â© 2026 Pierre Pluton. Tous droits rÃ©servÃ©s pour OpenClassrooms.
```

---

**Merci d'avoir reviewÃ© ce projet !** ğŸ‰  
**Contact** : [votre-email] | [LinkedIn/GitHub]
